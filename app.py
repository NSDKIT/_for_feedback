import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from collections import Counter
import numpy as np
import openai
import os
import json

# OpenAI APIã‚­ãƒ¼ã®è¨­å®š
try:
    openai.api_key = st.secrets["OPENAI_API_KEY"]
except Exception as e:
    st.error(f"OpenAI APIã‚­ãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    st.stop()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="æ¡ç”¨å‹•ç”»ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆçµæœåˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("æ¡ç”¨å‹•ç”»ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆçµæœåˆ†æ")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['csv'])

def analyze_with_openai(text, prompt):
    """OpenAI APIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã™ã‚‹"""
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯æ¡ç”¨å‹•ç”»ã®åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€å®¢è¦³çš„ã§å…·ä½“çš„ãªåˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": f"{prompt}\n\nåˆ†æå¯¾è±¡:\n{text}"}
            ],
            temperature=0.3,  # ã‚ˆã‚Šæ±ºå®šè«–çš„ãªå¿œç­”ã«
            max_tokens=2000   # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å¢—ã‚„ã™
        )
        return response.choices[0].message['content']
    except Exception as e:
        st.error(f"OpenAI APIã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None

def extract_questions(df):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è³ªå•é …ç›®ã‚’æŠ½å‡ºã™ã‚‹"""
    # å±æ€§æƒ…å ±ã®åˆ—å
    attribute_columns = ['å­¦å¹´', 'æ€§åˆ¥', 'å­¦éƒ¨ç³»çµ±']
    
    # ã¯ã„/ã„ã„ãˆè³ªå•ã®åˆ—åã‚’æŠ½å‡ºï¼ˆæ–‡é ­ãŒâš«ï¸ã§å§‹ã¾ã‚‹åˆ—ï¼‰
    yes_no_columns = [col for col in df.columns if col.startswith('âš«ï¸')]
    
    # ãã®ä»–ã®åˆ—ã‚’æŠ½å‡º
    other_columns = [col for col in df.columns if col not in attribute_columns and col not in yes_no_columns]
    
    # è‡ªç”±è¨˜è¿°å›ç­”ã®åˆ—åã‚’æŠ½å‡ºï¼ˆãã®ä»–ã®åˆ—ã‹ã‚‰é¸æŠï¼‰
    free_answer_columns = [col for col in other_columns if df[col].dtype == 'object']
    
    return {
        'attributes': attribute_columns,
        'yes_no': yes_no_columns,
        'free_answers': free_answer_columns
    }

if uploaded_file is not None:
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    df = pd.read_csv(uploaded_file)
    
    # è³ªå•é …ç›®ã®æŠ½å‡º
    questions = extract_questions(df)
    
    # ã‚¿ãƒ–ã®ä½œæˆ
    tab_attributes, tab_yes_no, tab_free_answers, tab_analysis = st.tabs([
        "å›ç­”è€…å±æ€§", "2æŠè³ªå•", "è‡ªç”±è¨˜è¿°", "ç·åˆåˆ†æ"
    ])
    
    # 1. å›ç­”è€…å±æ€§ã‚¿ãƒ–
    with tab_attributes:
        st.header("å›ç­”è€…å±æ€§")
        col1, col2, col3 = st.columns(3)
        
        for i, attr in enumerate(questions['attributes']):
            col = [col1, col2, col3][i]
            with col:
                counts = df[attr].value_counts()
                fig = px.pie(
                    values=counts.values,
                    names=counts.index,
                    title=f'{attr}åˆ†å¸ƒ'
                )
                st.plotly_chart(fig, use_container_width=True)
    
    # 2. 2æŠè³ªå•ã‚¿ãƒ–
    with tab_yes_no:
        st.header("2æŠè³ªå•ã®å›ç­”")
        cols = st.columns(2)
        for i, question in enumerate(questions['yes_no']):
            col = cols[i % 2]
            with col:
                yes_count = (df[question] == 'ã¯ã„').sum()
                no_count = (df[question] == 'ã„ã„ãˆ').sum()
                total = yes_count + no_count
                yes_percentage = (yes_count / total) * 100
                
                fig = go.Figure(data=[go.Pie(
                    labels=['ã¯ã„', 'ã„ã„ãˆ'],
                    values=[yes_count, no_count],
                    marker_colors=['#4CAF50', '#F44336']
                )])
                
                fig.update_layout(
                    title=f"{question}<br>ã¯ã„: {yes_percentage:.1f}%",
                    showlegend=True
                )
                
                st.plotly_chart(fig, use_container_width=True)
    
    # 3. è‡ªç”±è¨˜è¿°ã‚¿ãƒ–
    with tab_free_answers:
        st.header("è‡ªç”±è¨˜è¿°å›ç­”")
        
        # è‡ªç”±è¨˜è¿°å›ç­”ã®åˆ†æçµæœã‚’ä¿å­˜
        free_text_analysis = {}
        
        for field in questions['free_answers']:
            st.subheader(field)
            
            # å›ç­”ã®å–å¾—ã¨å‰å‡¦ç†
            answers = df[field].dropna().tolist()
            total_responses = len(answers)
            
            if total_responses > 0:
                # å›ç­”æ•°ã®è¡¨ç¤º
                st.markdown(f"**å›ç­”æ•°: {total_responses}ä»¶**")
                
                # é¡ä¼¼å›ç­”ã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆAIæ´»ç”¨ï¼‰
                grouping_prompt = """
                ä»¥ä¸‹ã®å›ç­”ã‚’æ„å‘³çš„ãªé¡ä¼¼æ€§ã«åŸºã¥ã„ã¦3-5å€‹ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†é¡ã—ã¦ãã ã•ã„ã€‚
                å„ã‚°ãƒ«ãƒ¼ãƒ—ã«ã¯ã€ãã®ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä»£è¡¨ã™ã‚‹å›ç­”ã¨ã€é¡ä¼¼ã™ã‚‹ä»–ã®å›ç­”ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
                å›ç­”ã¯åŸæ–‡ã®ã¾ã¾ä½¿ç”¨ã—ã€è¦ç´„ã‚„è¨€ã„æ›ãˆã¯é¿ã‘ã¦ãã ã•ã„ã€‚

                å‡ºåŠ›ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ï¼š
                {
                    "groups": [
                        {
                            "theme": "ã‚°ãƒ«ãƒ¼ãƒ—ã‚’è¡¨ã™çŸ­ã„ãƒ†ãƒ¼ãƒ",
                            "representative": "æœ€ã‚‚ä»£è¡¨çš„ãªå›ç­”ï¼ˆåŸæ–‡ï¼‰",
                            "similar_responses": ["é¡ä¼¼å›ç­”1", "é¡ä¼¼å›ç­”2", ...],
                            "similar_count": é¡ä¼¼å›ç­”ã®æ•°
                        }
                    ]
                }
                """
                
                # å›ç­”ã‚’AIã«é€ä¿¡ï¼ˆé•·ã™ãã‚‹å ´åˆã¯åˆ†å‰²ã—ã¦å‡¦ç†ï¼‰
                MAX_ANSWERS_PER_BATCH = 30  # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æ¸›ã‚‰ã™
                all_groups = []
                
                for i in range(0, len(answers), MAX_ANSWERS_PER_BATCH):
                    batch_answers = answers[i:i + MAX_ANSWERS_PER_BATCH]
                    analysis_text = "\n".join([f"- {answer}" for answer in batch_answers])
                    group_result = analyze_with_openai(analysis_text, grouping_prompt)
                    
                    if group_result:
                        try:
                            # JSONã®å‰å¾Œã®ä½™åˆ†ãªæ–‡å­—åˆ—ã‚’å‰Šé™¤
                            json_str = group_result.strip()
                            if not json_str.startswith('{'):
                                json_str = json_str[json_str.find('{'):]
                            if not json_str.endswith('}'):
                                json_str = json_str[:json_str.rfind('}')+1]
                            
                            result_dict = json.loads(json_str)
                            if 'groups' in result_dict:
                                all_groups.extend(result_dict['groups'])
                        except json.JSONDecodeError as e:
                            st.error(f"å›ç­”ã®åˆ†é¡ä¸­ã«JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                            continue
                        except Exception as e:
                            st.error(f"å›ç­”ã®åˆ†é¡ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                            continue
                
                if all_groups:
                    # ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«è¡¨ç¤º
                    for group in all_groups:
                        st.markdown(f"##### {group.get('theme', 'æœªåˆ†é¡ã‚°ãƒ«ãƒ¼ãƒ—')}")
                        
                        # ä»£è¡¨çš„ãªå›ç­”ã‚’è¡¨ç¤º
                        st.markdown("**ä»£è¡¨çš„ãªå›ç­”:**")
                        st.write(group.get('representative', ''))
                        
                        # é¡ä¼¼å›ç­”ã‚’è¡¨ç¤º
                        similar_responses = group.get('similar_responses', [])
                        if similar_responses:
                            similar_count = len(similar_responses)
                            st.markdown(f"**é¡ä¼¼ã™ã‚‹å›ç­” ({similar_count}ä»¶):**")
                            for response in similar_responses:
                                st.write(f"- {response}")
                        
                        st.write("---")
                
                # åˆ†é¡ã•ã‚Œãªã‹ã£ãŸå›ç­”ï¼ˆãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæ„è¦‹ï¼‰
                all_grouped_answers = set()
                for group in all_groups:
                    all_grouped_answers.add(group.get('representative', ''))
                    all_grouped_answers.update(group.get('similar_responses', []))
                
                unique_answers = [ans for ans in answers if ans not in all_grouped_answers]
                if unique_answers:
                    st.markdown("##### ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå›ç­”")
                    sample_size = min(10, len(unique_answers))
                    sample_unique = np.random.choice(unique_answers, size=sample_size, replace=False)
                    for answer in sample_unique:
                        st.write(f"- {answer}")
            else:
                st.info("ã“ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã¯å›ç­”ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            
            # åˆ†æçµæœã‚’ä¿å­˜ï¼ˆç·åˆåˆ†æã‚¿ãƒ–ã§ä½¿ç”¨ï¼‰
            free_text_analysis[field] = {
                'total': total_responses,
                'all_answers': answers,
                'grouped_answers': all_groups if total_responses > 0 else [],
                'unique_answers': unique_answers if total_responses > 0 else []
            }
            
            st.write("---")
    
    # 4. ç·åˆåˆ†æã‚¿ãƒ–
    with tab_analysis:
        st.header("ç·åˆåˆ†æ")
        
        # ç·åˆè©•ä¾¡
        st.subheader("1. ç·åˆè©•ä¾¡")
        
        # å‹•ç”»ã®è¦–è´ç‡ï¼ˆã‚µãƒ ãƒã‚¤ãƒ«ã®ç›®ç«‹ã¡åº¦ï¼‰
        thumbnail_question = next((q for q in questions['yes_no'] if 'ã‚µãƒ ãƒã‚¤ãƒ«' in q), None)
        if thumbnail_question:
            thumbnail_yes = (df[thumbnail_question] == 'ã¯ã„').sum()
            thumbnail_total = len(df)
            thumbnail_percentage = (thumbnail_yes / thumbnail_total) * 100
        else:
            thumbnail_percentage = 0
        
        # å†’é ­ã®å¼•ãè¾¼ã¿åŠ›
        intro_question = next((q for q in questions['yes_no'] if 'å†’é ­' in q), None)
        if intro_question:
            intro_yes = (df[intro_question] == 'ã¯ã„').sum()
            intro_percentage = (intro_yes / thumbnail_total) * 100
        else:
            intro_percentage = 0
        
        # ä¼šç¤¾ã®é›°å›²æ°—ä¼é”
        atmosphere_question = next((q for q in questions['yes_no'] if 'é›°å›²æ°—' in q), None)
        if atmosphere_question:
            atmosphere_yes = (df[atmosphere_question] == 'ã¯ã„').sum()
            atmosphere_percentage = (atmosphere_yes / thumbnail_total) * 100
        else:
            atmosphere_percentage = 0
        
        # å¿œå‹Ÿæ„å‘
        apply_question = next((q for q in questions['yes_no'] if 'å¿œå‹Ÿ' in q), None)
        if apply_question:
            apply_yes = (df[apply_question] == 'ã¯ã„').sum()
            apply_percentage = (apply_yes / thumbnail_total) * 100
        else:
            apply_percentage = 0
        
        # ç·åˆè©•ä¾¡ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
        evaluation_text = f"""
        å‹•ç”»ã®è¦–è´ç‡: {thumbnail_percentage:.1f}%
        å†’é ­ã®å¼•ãè¾¼ã¿åŠ›: {intro_percentage:.1f}%
        ä¼šç¤¾ã®é›°å›²æ°—ä¼é”: {atmosphere_percentage:.1f}%
        å¿œå‹Ÿæ„å‘: {apply_percentage:.1f}%
        """
        
        # OpenAIã«ã‚ˆã‚‹ç·åˆè©•ä¾¡ã®åˆ†æ
        evaluation_prompt = """
        ä»¥ä¸‹ã®æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æ¡ç”¨å‹•ç”»ã®ç·åˆè©•ä¾¡ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
        å…·ä½“çš„ãªæ•°å€¤ã«åŸºã¥ã„ã¦ã€å¼·ã¿ã¨æ”¹å–„ç‚¹ã‚’æ˜ç¢ºã«ç¤ºã—ã¦ãã ã•ã„ã€‚
        """
        evaluation_result = analyze_with_openai(evaluation_text, evaluation_prompt)
        
        if evaluation_result:
            st.write(evaluation_result)
        
        # ç¾çŠ¶ã®å¼·ã¿
        st.subheader("2. ç¾çŠ¶ã®å¼·ã¿")
        
        # å°è±¡ã®åˆ†æã‹ã‚‰å¼·ã¿ã‚’æŠ½å‡º
        impression_field = next((f for f in questions['free_answers'] if 'å°è±¡' in f), None)
        if impression_field and impression_field in free_text_analysis:
            impression_analysis = free_text_analysis[impression_field]
            top_impressions = [imp[0] for imp in impression_analysis['top_answers'][:3]]
            
            # å¼·ã¿ã®åˆ†æãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
            strengths_text = f"""
            ä¸»ãªå°è±¡: {', '.join(top_impressions)}
            å‹•ç”»ã®è©•ä¾¡æŒ‡æ¨™:
            - å¼•ãè¾¼ã¿åŠ›: {intro_percentage:.1f}%
            - é›°å›²æ°—ä¼é”: {atmosphere_percentage:.1f}%
            """
            
            # OpenAIã«ã‚ˆã‚‹å¼·ã¿ã®åˆ†æ
            strengths_prompt = """
            ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€ä¼æ¥­ã®å¼·ã¿ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚
            ç‰¹ã«æ¡ç”¨å‹•ç”»ã‚’é€šã˜ã¦ä¼ã‚ã£ã¦ã„ã‚‹ä¼æ¥­ã®ç‰¹å¾´ã‚„é­…åŠ›ã‚’å…·ä½“çš„ã«æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚
            """
            strengths_result = analyze_with_openai(strengths_text, strengths_prompt)
            
            if strengths_result:
                st.write(strengths_result)
        
        # ä¸»è¦ãªèª²é¡Œ
        st.subheader("3. ä¸»è¦ãªèª²é¡Œ")
        
        # æ¬²ã—ã„æƒ…å ±ã®åˆ†æã‹ã‚‰èª²é¡Œã‚’æŠ½å‡º
        desired_info_field = next((f for f in questions['free_answers'] if 'æƒ…å ±' in f), None)
        if desired_info_field and desired_info_field in free_text_analysis:
            desired_info = free_text_analysis[desired_info_field]
            top_desired_info = [info[0] for info in desired_info['top_answers'][:3]]
            
            # èª²é¡Œã®åˆ†æãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
            challenges_text = f"""
            ä¸è¶³ã—ã¦ã„ã‚‹æƒ…å ±: {', '.join(top_desired_info)}
            ç¾åœ¨ã®æŒ‡æ¨™:
            - å¿œå‹Ÿæ„å‘: {apply_percentage:.1f}%
            - æƒ…å ±å……å®Ÿåº¦: {atmosphere_percentage:.1f}%
            """
            
            # OpenAIã«ã‚ˆã‚‹èª²é¡Œã®åˆ†æ
            challenges_prompt = """
            ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æ¡ç”¨å‹•ç”»ã®ä¸»è¦ãªèª²é¡Œã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚
            ç‰¹ã«æ”¹å–„ãŒå¿…è¦ãªç‚¹ã‚„ã€å­¦ç”ŸãŒæ±‚ã‚ã‚‹æƒ…å ±ã¨ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’å…·ä½“çš„ã«æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚
            """
            challenges_result = analyze_with_openai(challenges_text, challenges_prompt)
            
            if challenges_result:
                st.write(challenges_result)
        
        # æ”¹å–„ææ¡ˆã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³
        st.subheader("4. æ”¹å–„ææ¡ˆã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³")
        
        if 'challenges_result' in locals():
            # çŸ­æœŸçš„ãªæ”¹å–„æ¡ˆ
            st.markdown("#### çŸ­æœŸçš„ãªæ”¹å–„æ¡ˆï¼ˆ1-3ãƒ¶æœˆï¼‰")
            short_term_prompt = f"""
            ä»¥ä¸‹ã®èª²é¡Œã¨æŒ‡æ¨™ã«åŸºã¥ã„ã¦ã€çŸ­æœŸçš„ï¼ˆ1-3ãƒ¶æœˆï¼‰ãªæ”¹å–„æ¡ˆã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚
            ã™ãã«ç€æ‰‹å¯èƒ½ã§ã€æ¯”è¼ƒçš„æ—©ãåŠ¹æœãŒå‡ºã‚‹æ–½ç­–ã‚’å„ªå…ˆçš„ã«ææ¡ˆã—ã¦ãã ã•ã„ã€‚
            
            ä¸»ãªèª²é¡Œ:
            {challenges_result}
            
            ç¾åœ¨ã®æŒ‡æ¨™:
            - å¼•ãè¾¼ã¿åŠ›: {intro_percentage:.1f}%
            - å¿œå‹Ÿæ„å‘: {apply_percentage:.1f}%
            """
            short_term_result = analyze_with_openai(short_term_prompt, "çŸ­æœŸçš„ãªæ”¹å–„æ¡ˆã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚")
            if short_term_result:
                st.write(short_term_result)
            
            # ä¸­æœŸçš„ãªæ”¹å–„æ¡ˆ
            st.markdown("#### ä¸­æœŸçš„ãªæ”¹å–„æ¡ˆï¼ˆ3-6ãƒ¶æœˆï¼‰")
            mid_term_prompt = f"""
            ä»¥ä¸‹ã®èª²é¡Œã¨æŒ‡æ¨™ã«åŸºã¥ã„ã¦ã€ä¸­æœŸçš„ï¼ˆ3-6ãƒ¶æœˆï¼‰ãªæ”¹å–„æ¡ˆã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚
            æº–å‚™ã«æ™‚é–“ãŒã‹ã‹ã‚‹ãŒã€ã‚ˆã‚Šæœ¬è³ªçš„ãªæ”¹å–„ã«ã¤ãªãŒã‚‹æ–½ç­–ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
            
            ä¸»ãªèª²é¡Œ:
            {challenges_result}
            
            ç¾åœ¨ã®æŒ‡æ¨™:
            - å¼•ãè¾¼ã¿åŠ›: {intro_percentage:.1f}%
            - å¿œå‹Ÿæ„å‘: {apply_percentage:.1f}%
            """
            mid_term_result = analyze_with_openai(mid_term_prompt, "ä¸­æœŸçš„ãªæ”¹å–„æ¡ˆã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚")
            if mid_term_result:
                st.write(mid_term_result)
            
            # é•·æœŸçš„ãªæ”¹å–„æ¡ˆ
            st.markdown("#### é•·æœŸçš„ãªæ”¹å–„æ¡ˆï¼ˆ6ãƒ¶æœˆ-1å¹´ï¼‰")
            long_term_prompt = f"""
            ä»¥ä¸‹ã®èª²é¡Œã¨æŒ‡æ¨™ã«åŸºã¥ã„ã¦ã€é•·æœŸçš„ï¼ˆ6ãƒ¶æœˆ-1å¹´ï¼‰ãªæ”¹å–„æ¡ˆã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚
            æ¡ç”¨å‹•ç”»ã®æ ¹æœ¬çš„ãªæ”¹å–„ã‚„ã€æ¡ç”¨æˆ¦ç•¥å…¨ä½“ã®è¦‹ç›´ã—ã«ã¤ãªãŒã‚‹æ–½ç­–ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
            
            ä¸»ãªèª²é¡Œ:
            {challenges_result}
            
            ç¾åœ¨ã®æŒ‡æ¨™:
            - å¼•ãè¾¼ã¿åŠ›: {intro_percentage:.1f}%
            - å¿œå‹Ÿæ„å‘: {apply_percentage:.1f}%
            """
            long_term_result = analyze_with_openai(long_term_prompt, "é•·æœŸçš„ãªæ”¹å–„æ¡ˆã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚")
            if long_term_result:
                st.write(long_term_result) 