import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from scipy.stats import chi2_contingency
import networkx as nx
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import itertools
import os
from openai import OpenAI

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="æ¡ç”¨å‹•ç”»ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆçµæœåˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# OpenAI APIã‚­ãƒ¼ã®è¨­å®š
try:
    api_key = st.secrets["OPENAI_API_KEY"]
    client = OpenAI(api_key=api_key)
except Exception as e:
    st.error(f"OpenAI APIã‚­ãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    st.stop()

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = ['Noto Sans CJK JP', 'Hiragino Sans', 'Yu Gothic', 'Meiryo', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic']

def analyze_free_text_with_openai(text_series):
    """OpenAI APIã‚’ä½¿ç”¨ã—ãŸè‡ªç”±è¨˜è¿°ã®åˆ†æï¼ˆæ§‹é€ åŒ–ã•ã‚ŒãŸå‡ºåŠ›å½¢å¼ï¼‰"""
    results = []
    
    # ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆã—ã¦åˆ†æç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
    combined_text = ' '.join(text_series.dropna())
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    prompt_template = """
    ä»¥ä¸‹ã®è‡ªç”±è¨˜è¿°ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆå›ç­”ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚å›ç­”è€…ã®æ„è¦‹ã€æ„Ÿæƒ³ã€ææ¡ˆã‚’ä½“ç³»çš„ã«æ•´ç†ã—ã€ä»¥ä¸‹ã®å½¢å¼ã§çµæœã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

    ã€åˆ†æå¯¾è±¡ã€‘
    {text}

    ã€åˆ†æçµæœã€‘
    1. ä¸»è¦ãƒ†ãƒ¼ãƒï¼ˆ5ã¤ã¾ã§ã€é‡è¦åº¦é †ï¼‰:
       - ãƒ†ãƒ¼ãƒ1: [ãƒ†ãƒ¼ãƒå] - [ç°¡æ½”ãªèª¬æ˜]
       - ãƒ†ãƒ¼ãƒ2: [ãƒ†ãƒ¼ãƒå] - [ç°¡æ½”ãªèª¬æ˜]
       ...

    2. é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆ10å€‹ã¾ã§ã€å‡ºç¾é »åº¦é †ï¼‰:
       - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1: [å‡ºç¾å›æ•°]
       - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2: [å‡ºç¾å›æ•°]
       ...

    3. æ„Ÿæƒ…åˆ†æ:
       - ãƒã‚¸ãƒ†ã‚£ãƒ–ãªæ„è¦‹: [å‰²åˆ]%
       - ãƒã‚¬ãƒ†ã‚£ãƒ–ãªæ„è¦‹: [å‰²åˆ]%
       - ä¸­ç«‹çš„ãªæ„è¦‹: [å‰²åˆ]%
       - ä¸»ãªãƒã‚¸ãƒ†ã‚£ãƒ–ãƒã‚¤ãƒ³ãƒˆ: [ç°¡æ½”ã«ç®‡æ¡æ›¸ã]
       - ä¸»ãªãƒã‚¬ãƒ†ã‚£ãƒ–ãƒã‚¤ãƒ³ãƒˆ: [ç°¡æ½”ã«ç®‡æ¡æ›¸ã]

    4. ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã®æ„è¦‹ï¼ˆé‡è¦ãªé †ã«5ã¤ã¾ã§ï¼‰:
       - ã‚«ãƒ†ã‚´ãƒªãƒ¼1: 
         * ä¸»ãªæ„è¦‹: [ç°¡æ½”ã«è¦ç´„]
         * å…·ä½“çš„ãªææ¡ˆ: [ã‚ã‚Œã°è¨˜è¼‰]
       - ã‚«ãƒ†ã‚´ãƒªãƒ¼2:
         * ä¸»ãªæ„è¦‹: [ç°¡æ½”ã«è¦ç´„]
         * å…·ä½“çš„ãªææ¡ˆ: [ã‚ã‚Œã°è¨˜è¼‰]
       ...

    5. ç‰¹ç­†ã™ã¹ãå°‘æ•°æ„è¦‹ï¼ˆ3ã¤ã¾ã§ï¼‰:
       - [æ„è¦‹1ã®è¦ç´„]
       - [æ„è¦‹2ã®è¦ç´„]
       - [æ„è¦‹3ã®è¦ç´„]

    6. ç·åˆåˆ†æï¼ˆ200å­—ä»¥å†…ï¼‰:
       [ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆå…¨ä½“ã®å‚¾å‘ã€ä¸»ãªç™ºè¦‹ã€ç¤ºå”†ã•ã‚Œã‚‹å¯¾å¿œç­–ãªã©ã‚’ç°¡æ½”ã«è¨˜è¼‰]

    7. ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ï¼ˆå„ªå…ˆåº¦é †ã«3ã¤ã¾ã§ï¼‰:
       - [å…·ä½“çš„ãªè¡Œå‹•ææ¡ˆ1]
       - [å…·ä½“çš„ãªè¡Œå‹•ææ¡ˆ2]
       - [å…·ä½“çš„ãªè¡Œå‹•ææ¡ˆ3]
    """
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãƒ†ã‚­ã‚¹ãƒˆã‚’åŸ‹ã‚è¾¼ã‚€
    formatted_prompt = prompt_template.format(text=combined_text)
    
    try:
        # OpenAI APIã‚’ä½¿ç”¨ã—ã¦åˆ†æã‚’å®Ÿè¡Œ
        response = client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆåˆ†æã®å°‚é–€å®¶ã§ã™ã€‚"},
                {"role": "user", "content": formatted_prompt}
            ],
            temperature=0.7
        )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†
        if response and response.choices:
            analysis_result = response.choices[0].message.content
            results.append(analysis_result)
        else:
            results.append("åˆ†æçµæœã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        
    except Exception as e:
        st.error(f"OpenAI APIã‚’ä½¿ç”¨ã—ãŸåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        results.append(f"åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    return results

def analyze_free_text(df, text_columns):
    """è‡ªç”±è¨˜è¿°ã®åˆ†æï¼ˆOpenAI APIã®ã¿ï¼‰"""
    results = {}
    
    for column in text_columns:
        # OpenAI APIã‚’ä½¿ç”¨ã—ãŸåˆ†æ
        openai_analysis = analyze_free_text_with_openai(df[column])
        
        results[column] = {
            'openai_analysis': openai_analysis
        }
    
    return results

def process_ranked_attributes(df, question):
    """å±æ€§ãƒ‡ãƒ¼ã‚¿ç”¨ï¼šé †ä½ä»˜ãè¤‡æ•°å›ç­”ã®å‡¦ç†ï¼ˆå…¨ä½“åˆ†å¸ƒã‚‚è¿”ã™ï¼‰"""
    answers = []
    for response in df[question]:
        if pd.isna(response):
            continue
        items = [item.strip() for item in str(response).split('ã€')]
        
        # è³ªå•ã‚¿ã‚¤ãƒ—ã®åˆ¤å®š
        if "ï¼ˆä¸Šä½3ã¤ã¾ã§ï¼‰" in question:
            # ä¸Šä½3ã¤ã¾ã§ã®è³ªå•ã¯é †ä½ä»˜ãã§å‡¦ç†
            for rank, item in enumerate(items, 1):
                answers.append((item, rank))
        elif "ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰" in question:
            # è¤‡æ•°é¸æŠå¯ã®è³ªå•ã¯é †ä½ãªã—ã§å‡¦ç†
            for item in items:
                answers.append((item, None))
    
    if not answers:
        return {}
    
    result_df = pd.DataFrame(answers, columns=['å›ç­”', 'é †ä½'])
    rank_distributions = {}
    
    if "ï¼ˆä¸Šä½3ã¤ã¾ã§ï¼‰" in question:
        # ä¸Šä½3ã¤ã¾ã§ã®è³ªå•ã®å ´åˆã€é †ä½ã”ã¨ã®åˆ†å¸ƒã‚’è¨ˆç®—
        max_rank = result_df['é †ä½'].max()
        for rank in range(1, max_rank + 1):
            rank_answers = result_df[result_df['é †ä½'] == rank]['å›ç­”']
            if not rank_answers.empty:
                rank_distributions[f"{rank}ä½"] = rank_answers.value_counts()
    else:
        # è¤‡æ•°é¸æŠå¯ã®è³ªå•ã®å ´åˆã€å…¨ä½“ã®åˆ†å¸ƒã®ã¿ã‚’è¨ˆç®—
        all_counts = result_df['å›ç­”'].value_counts()
        rank_distributions['å…¨ä½“'] = all_counts
    
    return rank_distributions

def analyze_attributes(df, attributes):
    """å±æ€§ãƒ‡ãƒ¼ã‚¿ã®åˆ†æï¼ˆé€šå¸¸å±æ€§ï¼‹è¤‡æ•°å›ç­”å±æ€§ã®é †ä½åˆ†å¸ƒï¼‰"""
    stats = {}
    ranked_distributions = {}
    for attr in attributes:
        if "ï¼ˆä¸Šä½3ã¤ã¾ã§ï¼‰" in attr or "ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰" in attr:
            # è¤‡æ•°å›ç­”å±æ€§ã¯é †ä½ã”ã¨ã®åˆ†å¸ƒã‚’è¨ˆç®—
            ranked_distributions[attr] = process_ranked_attributes(df, attr)
        else:
            value_counts = df[attr].value_counts()
            stats[attr] = {
                'count': df[attr].count(),
                'unique': df[attr].nunique(),
                'top': value_counts.index[0] if not value_counts.empty else None,
                'freq': value_counts.iloc[0] if not value_counts.empty else 0,
                'distribution': value_counts.to_dict()
            }
    return stats, ranked_distributions

def analyze_yes_no_questions(df, yes_no_questions, attributes):
    """2æŠè³ªå•ã®åˆ†æ"""
    # 1. å›ç­”åˆ†å¸ƒã®é›†è¨ˆ
    response_dist = {}
    for question in yes_no_questions:
        if "ï¼ˆä¸Šä½3ã¤ã¾ã§ï¼‰" in question or "ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰" in question:
            # è¤‡æ•°å›ç­”ã®è³ªå•ã¯ç‰¹åˆ¥å‡¦ç†
            ranked_answers = process_ranked_attributes(df, question)
            if not ranked_answers:
                response_dist[question] = {}
            else:
                response_dist[question] = ranked_answers
        else:
            # é€šå¸¸ã®2æŠè³ªå•
            response_dist[question] = df[question].value_counts(normalize=True)
    
    return response_dist

def analyze_all_survey_responses(df, text_columns, attributes, yes_no_questions):
    """ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆå…¨ä½“ã®æˆ¦ç•¥åˆ†æï¼ˆå®šé‡ãƒ»å®šæ€§åˆ†æï¼‰"""
    # 1. å®šé‡åˆ†æã®æº–å‚™
    quantitative_analysis = {}
    
    # å±æ€§ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ
    for attr in attributes:
        if "ï¼ˆä¸Šä½3ã¤ã¾ã§ï¼‰" in attr or "ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰" in attr:
            # è¤‡æ•°å›ç­”ã®å‡¦ç†
            responses = []
            for response in df[attr].dropna():
                items = [item.strip() for item in str(response).split('ã€')]
                responses.extend(items)
            value_counts = pd.Series(responses).value_counts()
            quantitative_analysis[attr] = {
                'type': 'multiple_choice',
                'total_responses': len(responses),
                'unique_responses': len(value_counts),
                'top_responses': value_counts.head(5).to_dict(),
                'distribution': value_counts.to_dict()
            }
        else:
            # å˜ä¸€å›ç­”ã®å‡¦ç†
            value_counts = df[attr].value_counts()
            quantitative_analysis[attr] = {
                'type': 'single_choice',
                'total_responses': df[attr].count(),
                'unique_responses': df[attr].nunique(),
                'top_response': value_counts.index[0] if not value_counts.empty else None,
                'distribution': value_counts.to_dict()
            }
    
    # 2æŠè³ªå•ã®åˆ†æ
    for question in yes_no_questions:
        value_counts = df[question].value_counts(normalize=True)
        quantitative_analysis[question] = {
            'type': 'binary',
            'total_responses': df[question].count(),
            'distribution': value_counts.to_dict(),
            'positive_ratio': value_counts.get('ã¯ã„', 0)
        }
    
    # 2. å®šæ€§åˆ†æï¼ˆè‡ªç”±è¨˜è¿°ï¼‰
    all_responses = []
    for column in text_columns:
        responses = df[column].dropna()
        all_responses.extend(responses)
    
    combined_text = ' '.join(all_responses)
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    prompt_template = """
    ä»¥ä¸‹ã®æ¡ç”¨å‹•ç”»ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆã®åˆ†æçµæœã‚’ç·åˆçš„ã«è©•ä¾¡ã—ã€å®šé‡ãƒ»å®šæ€§ã®ä¸¡é¢ã‹ã‚‰æˆ¦ç•¥çš„ãªç¤ºå”†ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

    ã€å®šé‡åˆ†æçµæœã€‘
    {quantitative_summary}

    ã€è‡ªç”±è¨˜è¿°å›ç­”ã€‘
    {text}

    # å‡ºåŠ›å½¢å¼
    ##### å›ç­”è€…å±æ€§
       [ä¸»è¦ãªå±æ€§åˆ†å¸ƒã¨ç‰¹å¾´ã‚’è¦ç´„]

    ##### ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¦‹ã‚‹å¼·ã¿:
       - [å¼·ã¿1]: [å®šé‡çš„ãªè£ä»˜ã‘ã¨ã¨ã‚‚ã«èª¬æ˜]
       - [å¼·ã¿2]: [å®šé‡çš„ãªè£ä»˜ã‘ã¨ã¨ã‚‚ã«èª¬æ˜]
       - [å¼·ã¿3]: [å®šé‡çš„ãªè£ä»˜ã‘ã¨ã¨ã‚‚ã«èª¬æ˜]

    ##### ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¦‹ã‚‹èª²é¡Œ:
       - [èª²é¡Œ1]: [å®šé‡çš„ãªè£ä»˜ã‘ã¨æƒ³å®šã•ã‚Œã‚‹å½±éŸ¿]
       - [èª²é¡Œ2]: [å®šé‡çš„ãªè£ä»˜ã‘ã¨æƒ³å®šã•ã‚Œã‚‹å½±éŸ¿]
       - [èª²é¡Œ3]: [å®šé‡çš„ãªè£ä»˜ã‘ã¨æƒ³å®šã•ã‚Œã‚‹å½±éŸ¿]

    ##### ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³:
        çŸ­æœŸçš„ãªæ”¹å–„æ–½ç­– (1-3ãƒ¶æœˆ):
            - [ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãå…·ä½“çš„ãªæ–½ç­–1]
            - [ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãå…·ä½“çš„ãªæ–½ç­–2]
            - [ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãå…·ä½“çš„ãªæ–½ç­–3]
    
        ä¸­æœŸçš„ãªæˆ¦ç•¥æ–½ç­– (3-6ãƒ¶æœˆ):
            - [ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãå…·ä½“çš„ãªæ–½ç­–1]
            - [ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãå…·ä½“çš„ãªæ–½ç­–2]
            - [ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãå…·ä½“çš„ãªæ–½ç­–3]
    
        é•·æœŸçš„ãªæˆ¦ç•¥è»¢æ› (6ãƒ¶æœˆä»¥ä¸Š):
            - [ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãå…·ä½“çš„ãªæ–½ç­–1]
            - [ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãå…·ä½“çš„ãªæ–½ç­–2]
            - [ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãå…·ä½“çš„ãªæ–½ç­–3]

    """
    
    # å®šé‡åˆ†æã®ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ
    quantitative_summary = []
    
    # å±æ€§ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒãƒªãƒ¼
    for attr, data in quantitative_analysis.items():
        if data['type'] == 'multiple_choice':
            summary = f"{attr}ã®ä¸Šä½å›ç­”: " + ", ".join([f"{k}({v}ä»¶)" for k, v in data['top_responses'].items()])
        elif data['type'] == 'single_choice':
            summary = f"{attr}ã®æœ€é »å€¤: {data['top_response']} ({data['distribution'][data['top_response']]}ä»¶)"
        else:  # binary
            summary = f"{attr}ã®è‚¯å®šçš„å›ç­”ç‡: {data.get('positive_ratio', 0)*100:.1f}%"
        quantitative_summary.append(summary)
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãƒ‡ãƒ¼ã‚¿ã‚’åŸ‹ã‚è¾¼ã‚€
    formatted_prompt = prompt_template.format(
        quantitative_summary="\n".join(quantitative_summary),
        text=combined_text
    )
    
    try:
        # OpenAI APIã‚’ä½¿ç”¨ã—ã¦åˆ†æã‚’å®Ÿè¡Œ
        response = client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆåˆ†æã¨æ¡ç”¨æˆ¦ç•¥ã®å°‚é–€å®¶ã§ã™ã€‚"},
                {"role": "user", "content": formatted_prompt}
            ],
            temperature=0.7
        )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†
        if response and response.choices:
            return {
                'quantitative_analysis': quantitative_analysis,
                'strategic_analysis': response.choices[0].message.content
            }
        else:
            return {
                'quantitative_analysis': quantitative_analysis,
                'strategic_analysis': "åˆ†æçµæœã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
            }
        
    except Exception as e:
        st.error(f"OpenAI APIã‚’ä½¿ç”¨ã—ãŸåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return {
            'quantitative_analysis': quantitative_analysis,
            'strategic_analysis': f"åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {str(e)}"
        }

def visualize_analysis(df, attributes, yes_no_questions, text_columns):
    """åˆ†æçµæœã®å¯è¦–åŒ–"""
    # å±æ€§ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ
    stats, attribute_ranked = analyze_attributes(df, attributes)
    # 2æŠè³ªå•ã®åˆ†æ
    response_dist = analyze_yes_no_questions(df, yes_no_questions, attributes)
    # è‡ªç”±è¨˜è¿°ã®åˆ†æ
    text_analysis = analyze_free_text(df, text_columns)
    # å…¨ä½“ã®æˆ¦ç•¥åˆ†æï¼ˆå®šé‡ãƒ»å®šæ€§ï¼‰
    comprehensive_analysis = analyze_all_survey_responses(df, text_columns, attributes, yes_no_questions)
    
    return {
        'stats': stats,
        'attribute_ranked': attribute_ranked,
        'response_dist': response_dist,
        'text_analysis': text_analysis,
        'comprehensive_analysis': comprehensive_analysis
    }

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("æ¡ç”¨å‹•ç”»ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆçµæœåˆ†æ")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['csv'])

if uploaded_file is not None:
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    df = pd.read_csv(uploaded_file)
    
    # è³ªå•ã®åˆ†é¡
    attributes = [col for col in df.columns if 'â–ªï¸' in col]
    yes_no_questions = [col for col in df.columns if 'ãƒ»' in col]
    text_columns = [col for col in df.columns if '#' in col]
    
    # åˆ†æã®å®Ÿè¡Œ
    analysis_results = visualize_analysis(df, attributes, yes_no_questions, text_columns)
    
    # ã‚¿ãƒ–ã®ä½œæˆ
    tab_attributes, tab_yes_no, tab_text, tab_cross, tab_strategic = st.tabs([
        "1. å±æ€§åˆ†æ",
        "2. 2æŠè³ªå•åˆ†æ",
        "3. è‡ªç”±è¨˜è¿°åˆ†æ",
        "4. ã‚¯ãƒ­ã‚¹åˆ†æ",
        "5. ç·åˆåˆ†æ"
    ])
    
    # 1. å±æ€§åˆ†æã‚¿ãƒ–
    with tab_attributes:
        # 3åˆ—ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’ä½œæˆ
        cols = st.columns(3)
        col_index = 0
        
        for attr in attributes:
            if "ï¼ˆä¸Šä½3ã¤ã¾ã§ï¼‰" in attr or "ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰" in attr:
                # è¤‡æ•°å›ç­”ã®è³ªå•ã¯è³ªå•ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦å‡¦ç†
                rank_distributions = analysis_results['attribute_ranked'].get(attr, {})
                
                if "ï¼ˆä¸Šä½3ã¤ã¾ã§ï¼‰" in attr:
                    # ä¸Šä½3ã¤ã¾ã§ã®è³ªå•ã¯é †ä½ã”ã¨ã«ç‹¬ç«‹ã—ãŸå›³ã‚’è¡¨ç¤º
                    rank_keys = [k for k in rank_distributions.keys() if k != 'å…¨ä½“']
                    for rank in sorted(rank_keys, key=lambda x: int(x.replace('ä½','')) if x.endswith('ä½') else 999):
                        with cols[col_index % 3]:
                            rank_dist = rank_distributions[rank]
                            # å›ç­”æ•°ã§ã‚½ãƒ¼ãƒˆ
                            sorted_dist = rank_dist.sort_values(ascending=False)
                            st.markdown(f"###### {attr} - {rank}")
                            fig = px.pie(
                                values=sorted_dist.values,
                                names=sorted_dist.index,
                                width=400,
                                height=400
                            )
                            fig.update_layout(
                                uniformtext_minsize=12,
                                uniformtext_mode='hide'
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        col_index += 1
                else:
                    # è¤‡æ•°é¸æŠå¯ã®è³ªå•ã¯å…¨ä½“ã®åˆ†å¸ƒã®ã¿ã‚’è¡¨ç¤º
                    with cols[col_index % 3]:
                        all_dist = rank_distributions.get('å…¨ä½“', pd.Series())
                        # å›ç­”æ•°ã§ã‚½ãƒ¼ãƒˆ
                        sorted_dist = all_dist.sort_values(ascending=False)
                        st.markdown(f"###### {attr}")
                        fig = px.pie(
                            values=sorted_dist.values,
                            names=sorted_dist.index,
                            width=400,
                            height=400
                        )
                        fig.update_layout(
                            uniformtext_minsize=12,
                            uniformtext_mode='hide'
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    col_index += 1
            else:
                # é€šå¸¸ã®å±æ€§ã¯1ã¤ã®å›³ã‚’è¡¨ç¤º
                with cols[col_index % 3]:
                    stat = analysis_results['stats'][attr]
                    # å›ç­”æ•°ã§ã‚½ãƒ¼ãƒˆ
                    sorted_dist = pd.Series(stat['distribution']).sort_values(ascending=False)
                    st.markdown(f"###### {attr}")
                    fig = px.pie(
                        values=sorted_dist.values,
                        names=sorted_dist.index,
                        width=400,
                        height=400
                    )
                    fig.update_layout(
                        uniformtext_minsize=12,
                        uniformtext_mode='hide'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                col_index += 1
    
    # 2. 2æŠè³ªå•åˆ†æã‚¿ãƒ–
    with tab_yes_no:
        # 3åˆ—ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’ä½œæˆ
        cols = st.columns(3)
        col_index = 0
        
        for question, dist in analysis_results['response_dist'].items():
            if "ï¼ˆä¸Šä½3ã¤ã¾ã§ï¼‰" in question or "ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰" in question:
                # è¤‡æ•°å›ç­”ã®è³ªå•ã¯è³ªå•ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦å‡¦ç†
                if "ï¼ˆä¸Šä½3ã¤ã¾ã§ï¼‰" in question:
                    # ä¸Šä½3ã¤ã¾ã§ã®è³ªå•ã¯é †ä½ã”ã¨ã®å††ã‚°ãƒ©ãƒ•
                    for rank, rank_dist in dist.items():
                        with cols[col_index % 3]:
                            # å›ç­”æ•°ã§ã‚½ãƒ¼ãƒˆ
                            sorted_dist = rank_dist.sort_values(ascending=False)
                            st.markdown(f"###### {question} - {rank}")
                            fig = px.pie(
                                values=sorted_dist.values,
                                names=sorted_dist.index,
                                width=400,
                                height=400
                            )
                            fig.update_layout(
                                uniformtext_minsize=12,
                                uniformtext_mode='hide'
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        col_index += 1
                else:
                    # è¤‡æ•°é¸æŠå¯ã®è³ªå•ã¯å…¨ä½“ã®åˆ†å¸ƒã®ã¿ã‚’è¡¨ç¤º
                    with cols[col_index % 3]:
                        all_dist = dist.get('å…¨ä½“', pd.Series())
                        # å›ç­”æ•°ã§ã‚½ãƒ¼ãƒˆ
                        sorted_dist = all_dist.sort_values(ascending=False)
                        st.markdown(f"###### {question}")
                        fig = px.pie(
                            values=sorted_dist.values,
                            names=sorted_dist.index,
                            width=400,
                            height=400
                        )
                        fig.update_layout(
                            uniformtext_minsize=12,
                            uniformtext_mode='hide'
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    col_index += 1
            else:
                # é€šå¸¸ã®2æŠè³ªå•
                with cols[col_index % 3]:
                    # å›ç­”æ•°ã§ã‚½ãƒ¼ãƒˆ
                    sorted_dist = dist.sort_values(ascending=False)
                    st.markdown(f"###### {question}")
                    fig = px.pie(
                        values=sorted_dist.values,
                        names=sorted_dist.index,
                        width=400,
                        height=400
                    )
                    fig.update_layout(
                        uniformtext_minsize=12,
                        uniformtext_mode='hide'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                col_index += 1
    
    # 3. è‡ªç”±è¨˜è¿°åˆ†æã‚¿ãƒ–
    with tab_text:        
        # è³ªå•ã”ã¨ã®ã‚µãƒ–ã‚¿ãƒ–ã‚’ä½œæˆ
        if analysis_results['text_analysis']:
            # ã‚µãƒ–ã‚¿ãƒ–ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            text_tabs = st.tabs([f"è³ªå•{i+1}: {column.split('#')[1] if '#' in column else column}" 
                               for i, column in enumerate(analysis_results['text_analysis'].keys())])
            
            # å„ã‚µãƒ–ã‚¿ãƒ–ã«åˆ†æçµæœã‚’è¡¨ç¤º
            for tab, (column, analysis) in zip(text_tabs, analysis_results['text_analysis'].items()):
                with tab:                    
                    # OpenAIã«ã‚ˆã‚‹åˆ†æçµæœã®è¡¨ç¤º
                    for result in analysis['openai_analysis']:
                        st.markdown(result)
                        
    # 4. ã‚¯ãƒ­ã‚¹åˆ†æã‚¿ãƒ–
    with tab_cross:
        def display_cross_analysis(df):
            tabs = st.tabs([
                "æ€§åˆ¥ Ã— èˆˆå‘³ã®ã‚ã‚‹æ¥­ç•Œ",
                "æ€§åˆ¥ Ã— èˆˆå‘³ã®ã‚ã‚‹è·ç¨®",
                "å­¦å¹´ Ã— èˆˆå‘³ã®ã‚ã‚‹æ¥­ç•Œ",
                "å­¦å¹´ Ã— èˆˆå‘³ã®ã‚ã‚‹è·ç¨®",
                "å‡ºèº«åœ° Ã— èˆˆå‘³ã®ã‚ã‚‹æ¥­ç•Œ",
                "å‡ºèº«åœ° Ã— èˆˆå‘³ã®ã‚ã‚‹è·ç¨®",
                "å­¦å¹´ Ã— æ†§ã‚Œã¦ã„ã‚‹æ¥­ç•Œ"
            ])

            # å®šç¾©: å„ã‚¯ãƒ­ã‚¹é›†è¨ˆã‚¿ãƒ–ã®æƒ…å ±
            cross_info = [
                ("â–ªï¸ æ€§åˆ¥", "â–ªï¸ èˆˆå‘³ã®ã‚ã‚‹æ¥­ç•Œ"),
                ("â–ªï¸ æ€§åˆ¥", "â–ªï¸ èˆˆå‘³ã®ã‚ã‚‹è·ç¨®"),
                ("â–ªï¸ å­¦å¹´", "â–ªï¸ èˆˆå‘³ã®ã‚ã‚‹æ¥­ç•Œ"),
                ("â–ªï¸ å­¦å¹´", "â–ªï¸ èˆˆå‘³ã®ã‚ã‚‹è·ç¨®"),
                ("â–ªï¸ å‡ºèº«åœ°", "â–ªï¸ èˆˆå‘³ã®ã‚ã‚‹æ¥­ç•Œ"),
                ("â–ªï¸ å‡ºèº«åœ°", "â–ªï¸ èˆˆå‘³ã®ã‚ã‚‹è·ç¨®"),
                ("â–ªï¸ å­¦å¹´", "â–ªï¸ æ†§ã‚Œã¦ã„ã‚‹æ¥­ç•Œ")
            ]

            for tab, (row_attr, col_attr) in zip(tabs, cross_info):
                with tab:
                    try:
                        ct = pd.crosstab(df[row_attr], df[col_attr])
                        ct = ct.loc[:, ct.sum().sort_values(ascending=False).index]  # ã‚«ãƒ©ãƒ ã‚’é »åº¦é †ã«

                        fig = px.bar(
                            ct.T,
                            barmode="stack",
                            title=f"{row_attr} Ã— {col_attr}"
                        )
                        fig.update_layout(xaxis_title=col_attr, yaxis_title="äººæ•°")
                        st.plotly_chart(fig, use_container_width=True)
                    except Exception as e:
                        st.warning(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

        # ã‚¯ãƒ­ã‚¹åˆ†æã®å®Ÿè¡Œ
        display_cross_analysis(df)

    # 5. æˆ¦ç•¥åˆ†æã‚¿ãƒ–
    with tab_strategic:
        if 'comprehensive_analysis' in analysis_results:
            # æˆ¦ç•¥åˆ†æçµæœã®è¡¨ç¤º
            st.markdown(analysis_results['comprehensive_analysis']['strategic_analysis'])
        else:
            st.warning("åˆ†æçµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")    