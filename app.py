import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from scipy.stats import chi2_contingency
import networkx as nx
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import re
from collections import Counter
import itertools
import os
import openai

# OpenAI APIã‚­ãƒ¼ã®è¨­å®š
try:
    api_key = st.secrets["OPENAI_API_KEY"]
    if not api_key:
        st.error("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop()
    # ç’°å¢ƒå¤‰æ•°ã«APIã‚­ãƒ¼ã‚’è¨­å®š
    os.environ["OPENAI_API_KEY"] = api_key
    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
    client = openai.OpenAI()
except Exception as e:
    st.error(f"OpenAI APIã‚­ãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    st.stop()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="æ¡ç”¨å‹•ç”»ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆçµæœåˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = ['Noto Sans CJK JP', 'Hiragino Sans', 'Yu Gothic', 'Meiryo', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic']

def analyze_free_text_with_openai(text_series):
    """OpenAI APIã‚’ä½¿ç”¨ã—ãŸè‡ªç”±è¨˜è¿°ã®åˆ†æ"""
    results = []
    
    # ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆã—ã¦åˆ†æç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
    combined_text = ' '.join(text_series.dropna())
    
    try:
        # OpenAI APIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚’å®Ÿè¡Œ
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ä¸»è¦ãªãƒ†ãƒ¼ãƒã‚„å‚¾å‘ã‚’æŠ½å‡ºã—ã€æ§‹é€ åŒ–ã•ã‚ŒãŸåˆ†æçµæœã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": f"ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã€ä¸»è¦ãªãƒ†ãƒ¼ãƒã€å‚¾å‘ã€é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€å…¨ä½“çš„ãªå°è±¡ã‚„ç‰¹å¾´ã‚‚å«ã‚ã¦ãã ã•ã„ã€‚\n\n{combined_text}"}
            ],
            temperature=0.7,
            max_tokens=1000
        )
        
        analysis_result = response.choices[0].message.content
        results.append(analysis_result)
        
    except Exception as e:
        st.error(f"OpenAI APIã‚’ä½¿ç”¨ã—ãŸåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        results.append("åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    
    return results

def analyze_free_text(df, text_columns):
    """è‡ªç”±è¨˜è¿°ã®åˆ†æï¼ˆOpenAI APIã®ã¿ï¼‰"""
    results = {}
    
    for column in text_columns:
        # OpenAI APIã‚’ä½¿ç”¨ã—ãŸåˆ†æ
        openai_analysis = analyze_free_text_with_openai(df[column])
        
        results[column] = {
            'openai_analysis': openai_analysis
        }
    
    return results

def process_ranked_attributes(df, question):
    """å±æ€§ãƒ‡ãƒ¼ã‚¿ç”¨ï¼šé †ä½ä»˜ãè¤‡æ•°å›ç­”ã®å‡¦ç†ï¼ˆå…¨ä½“åˆ†å¸ƒã‚‚è¿”ã™ï¼‰"""
    answers = []
    for response in df[question]:
        if pd.isna(response):
            continue
        items = [item.strip() for item in str(response).split('ã€')]
        
        # è³ªå•ã‚¿ã‚¤ãƒ—ã®åˆ¤å®š
        if "ï¼ˆä¸Šä½3ã¤ã¾ã§ï¼‰" in question:
            # ä¸Šä½3ã¤ã¾ã§ã®è³ªå•ã¯é †ä½ä»˜ãã§å‡¦ç†
            for rank, item in enumerate(items, 1):
                answers.append((item, rank))
        elif "ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰" in question:
            # è¤‡æ•°é¸æŠå¯ã®è³ªå•ã¯é †ä½ãªã—ã§å‡¦ç†
            for item in items:
                answers.append((item, None))
    
    if not answers:
        return {}
    
    result_df = pd.DataFrame(answers, columns=['å›ç­”', 'é †ä½'])
    rank_distributions = {}
    
    if "ï¼ˆä¸Šä½3ã¤ã¾ã§ï¼‰" in question:
        # ä¸Šä½3ã¤ã¾ã§ã®è³ªå•ã®å ´åˆã€é †ä½ã”ã¨ã®åˆ†å¸ƒã‚’è¨ˆç®—
        max_rank = result_df['é †ä½'].max()
        for rank in range(1, max_rank + 1):
            rank_answers = result_df[result_df['é †ä½'] == rank]['å›ç­”']
            if not rank_answers.empty:
                rank_distributions[f"{rank}ä½"] = rank_answers.value_counts()
    else:
        # è¤‡æ•°é¸æŠå¯ã®è³ªå•ã®å ´åˆã€å…¨ä½“ã®åˆ†å¸ƒã®ã¿ã‚’è¨ˆç®—
        all_counts = result_df['å›ç­”'].value_counts()
        rank_distributions['å…¨ä½“'] = all_counts
    
    return rank_distributions

def analyze_attributes(df, attributes):
    """å±æ€§ãƒ‡ãƒ¼ã‚¿ã®åˆ†æï¼ˆé€šå¸¸å±æ€§ï¼‹è¤‡æ•°å›ç­”å±æ€§ã®é †ä½åˆ†å¸ƒï¼‰"""
    stats = {}
    ranked_distributions = {}
    for attr in attributes:
        if "ï¼ˆä¸Šä½3ã¤ã¾ã§ï¼‰" in attr or "ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰" in attr:
            # è¤‡æ•°å›ç­”å±æ€§ã¯é †ä½ã”ã¨ã®åˆ†å¸ƒã‚’è¨ˆç®—
            ranked_distributions[attr] = process_ranked_attributes(df, attr)
        else:
            value_counts = df[attr].value_counts()
            stats[attr] = {
                'count': df[attr].count(),
                'unique': df[attr].nunique(),
                'top': value_counts.index[0] if not value_counts.empty else None,
                'freq': value_counts.iloc[0] if not value_counts.empty else 0,
                'distribution': value_counts.to_dict()
            }
    return stats, ranked_distributions

def analyze_yes_no_questions(df, yes_no_questions, attributes):
    """2æŠè³ªå•ã®åˆ†æ"""
    # 1. å›ç­”åˆ†å¸ƒã®é›†è¨ˆ
    response_dist = {}
    for question in yes_no_questions:
        if "ï¼ˆä¸Šä½3ã¤ã¾ã§ï¼‰" in question or "ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰" in question:
            # è¤‡æ•°å›ç­”ã®è³ªå•ã¯ç‰¹åˆ¥å‡¦ç†
            ranked_answers = process_ranked_attributes(df, question)
            if not ranked_answers:
                response_dist[question] = {}
            else:
                response_dist[question] = ranked_answers
        else:
            # é€šå¸¸ã®2æŠè³ªå•
            response_dist[question] = df[question].value_counts(normalize=True)
    
    return response_dist

def visualize_analysis(df, attributes, yes_no_questions, text_columns):
    """åˆ†æçµæœã®å¯è¦–åŒ–"""
    # å±æ€§ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ
    stats, attribute_ranked = analyze_attributes(df, attributes)
    # 2æŠè³ªå•ã®åˆ†æ
    response_dist = analyze_yes_no_questions(df, yes_no_questions, attributes)
    # è‡ªç”±è¨˜è¿°ã®åˆ†æ
    text_analysis = analyze_free_text(df, text_columns)
    return {
        'stats': stats,
        'attribute_ranked': attribute_ranked,
        'response_dist': response_dist,
        'text_analysis': text_analysis
    }

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("æ¡ç”¨å‹•ç”»ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆçµæœåˆ†æ")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['csv'])

if uploaded_file is not None:
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    df = pd.read_csv(uploaded_file)
    
    # è³ªå•ã®åˆ†é¡
    attributes = [col for col in df.columns if 'â–ªï¸' in col]
    yes_no_questions = [col for col in df.columns if 'ãƒ»' in col]
    text_columns = [col for col in df.columns if '#' in col]
    
    # åˆ†æã®å®Ÿè¡Œ
    analysis_results = visualize_analysis(df, attributes, yes_no_questions, text_columns)
    
    # ã‚¿ãƒ–ã®ä½œæˆ
    tab_attributes, tab_yes_no, tab_text, tab_summary = st.tabs([
        "1. å±æ€§åˆ†æ",
        "2. 2æŠè³ªå•åˆ†æ",
        "3. è‡ªç”±è¨˜è¿°åˆ†æ",
        "4. ç·åˆåˆ†æ"
    ])
    
    # 1. å±æ€§åˆ†æã‚¿ãƒ–
    with tab_attributes:
        st.markdown("### 1. å±æ€§åˆ†æ")
        # 3åˆ—ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’ä½œæˆ
        cols = st.columns(3)
        col_index = 0
        
        for attr in attributes:
            if "ï¼ˆä¸Šä½3ã¤ã¾ã§ï¼‰" in attr or "ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰" in attr:
                # è¤‡æ•°å›ç­”ã®è³ªå•ã¯è³ªå•ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦å‡¦ç†
                rank_distributions = analysis_results['attribute_ranked'].get(attr, {})
                
                if "ï¼ˆä¸Šä½3ã¤ã¾ã§ï¼‰" in attr:
                    # ä¸Šä½3ã¤ã¾ã§ã®è³ªå•ã¯é †ä½ã”ã¨ã«ç‹¬ç«‹ã—ãŸå›³ã‚’è¡¨ç¤º
                    rank_keys = [k for k in rank_distributions.keys() if k != 'å…¨ä½“']
                    for rank in sorted(rank_keys, key=lambda x: int(x.replace('ä½','')) if x.endswith('ä½') else 999):
                        with cols[col_index % 3]:
                            rank_dist = rank_distributions[rank]
                            # å›ç­”æ•°ã§ã‚½ãƒ¼ãƒˆ
                            sorted_dist = rank_dist.sort_values(ascending=False)
                            st.markdown(f"###### {attr} - {rank}")
                            fig = px.pie(
                                values=sorted_dist.values,
                                names=sorted_dist.index,
                                width=400,
                                height=400
                            )
                            fig.update_layout(
                                uniformtext_minsize=12,
                                uniformtext_mode='hide'
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        col_index += 1
                else:
                    # è¤‡æ•°é¸æŠå¯ã®è³ªå•ã¯å…¨ä½“ã®åˆ†å¸ƒã®ã¿ã‚’è¡¨ç¤º
                    with cols[col_index % 3]:
                        all_dist = rank_distributions.get('å…¨ä½“', pd.Series())
                        # å›ç­”æ•°ã§ã‚½ãƒ¼ãƒˆ
                        sorted_dist = all_dist.sort_values(ascending=False)
                        st.markdown(f"###### {attr}")
                        fig = px.pie(
                            values=sorted_dist.values,
                            names=sorted_dist.index,
                            width=400,
                            height=400
                        )
                        fig.update_layout(
                            uniformtext_minsize=12,
                            uniformtext_mode='hide'
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    col_index += 1
            else:
                # é€šå¸¸ã®å±æ€§ã¯1ã¤ã®å›³ã‚’è¡¨ç¤º
                with cols[col_index % 3]:
                    stat = analysis_results['stats'][attr]
                    # å›ç­”æ•°ã§ã‚½ãƒ¼ãƒˆ
                    sorted_dist = pd.Series(stat['distribution']).sort_values(ascending=False)
                    st.markdown(f"###### {attr}")
                    fig = px.pie(
                        values=sorted_dist.values,
                        names=sorted_dist.index,
                        width=400,
                        height=400
                    )
                    fig.update_layout(
                        uniformtext_minsize=12,
                        uniformtext_mode='hide'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                col_index += 1
    
    # 2. 2æŠè³ªå•åˆ†æã‚¿ãƒ–
    with tab_yes_no:
        st.markdown("### 2. 2æŠè³ªå•åˆ†æ")
        
        # å›ç­”åˆ†å¸ƒã®è¡¨ç¤º
        st.markdown("#### å›ç­”åˆ†å¸ƒ")
        # 3åˆ—ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’ä½œæˆ
        cols = st.columns(3)
        col_index = 0
        
        for question, dist in analysis_results['response_dist'].items():
            if "ï¼ˆä¸Šä½3ã¤ã¾ã§ï¼‰" in question or "ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰" in question:
                # è¤‡æ•°å›ç­”ã®è³ªå•ã¯è³ªå•ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦å‡¦ç†
                if "ï¼ˆä¸Šä½3ã¤ã¾ã§ï¼‰" in question:
                    # ä¸Šä½3ã¤ã¾ã§ã®è³ªå•ã¯é †ä½ã”ã¨ã®å††ã‚°ãƒ©ãƒ•
                    for rank, rank_dist in dist.items():
                        with cols[col_index % 3]:
                            # å›ç­”æ•°ã§ã‚½ãƒ¼ãƒˆ
                            sorted_dist = rank_dist.sort_values(ascending=False)
                            st.markdown(f"###### {question} - {rank}")
                            fig = px.pie(
                                values=sorted_dist.values,
                                names=sorted_dist.index,
                                width=400,
                                height=400
                            )
                            fig.update_layout(
                                uniformtext_minsize=12,
                                uniformtext_mode='hide'
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        col_index += 1
                else:
                    # è¤‡æ•°é¸æŠå¯ã®è³ªå•ã¯å…¨ä½“ã®åˆ†å¸ƒã®ã¿ã‚’è¡¨ç¤º
                    with cols[col_index % 3]:
                        all_dist = dist.get('å…¨ä½“', pd.Series())
                        # å›ç­”æ•°ã§ã‚½ãƒ¼ãƒˆ
                        sorted_dist = all_dist.sort_values(ascending=False)
                        st.markdown(f"###### {question}")
                        fig = px.pie(
                            values=sorted_dist.values,
                            names=sorted_dist.index,
                            width=400,
                            height=400
                        )
                        fig.update_layout(
                            uniformtext_minsize=12,
                            uniformtext_mode='hide'
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    col_index += 1
            else:
                # é€šå¸¸ã®2æŠè³ªå•
                with cols[col_index % 3]:
                    # å›ç­”æ•°ã§ã‚½ãƒ¼ãƒˆ
                    sorted_dist = dist.sort_values(ascending=False)
                    st.markdown(f"###### {question}")
                    fig = px.pie(
                        values=sorted_dist.values,
                        names=sorted_dist.index,
                        width=400,
                        height=400
                    )
                    fig.update_layout(
                        uniformtext_minsize=12,
                        uniformtext_mode='hide'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                col_index += 1
    
    # 3. è‡ªç”±è¨˜è¿°åˆ†æã‚¿ãƒ–
    with tab_text:
        st.markdown("### 3. è‡ªç”±è¨˜è¿°åˆ†æ")
        
        for column, analysis in analysis_results['text_analysis'].items():
            st.markdown(f"#### {column}")
            
            # OpenAIã«ã‚ˆã‚‹åˆ†æçµæœã®è¡¨ç¤º
            st.markdown("##### AIã«ã‚ˆã‚‹åˆ†æ")
            for result in analysis['openai_analysis']:
                st.write(result)
    
    # 4. ç·åˆåˆ†æã‚¿ãƒ–
    with tab_summary:
        st.markdown("### 4. ç·åˆåˆ†æ")
        
        # ä¸»æˆåˆ†åˆ†æ
        st.markdown("#### ä¸»æˆåˆ†åˆ†æ")
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        if len(numeric_columns) > 0:
            pca = PCA(n_components=2)
            pca_result = pca.fit_transform(df[numeric_columns])
            fig = px.scatter(
                x=pca_result[:, 0],
                y=pca_result[:, 1],
                title="ä¸»æˆåˆ†åˆ†æçµæœ"
            )
            st.plotly_chart(fig)
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æ
        st.markdown("#### ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æ")
        if len(numeric_columns) > 0:
            kmeans = KMeans(n_clusters=3)
            clusters = kmeans.fit_predict(df[numeric_columns])
            fig = px.scatter(
                x=pca_result[:, 0],
                y=pca_result[:, 1],
                color=clusters,
                title="ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æçµæœ"
            )
            st.plotly_chart(fig)    